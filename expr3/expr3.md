# 实验三 AI 短视频制作

## 一、实验基本信息

- 实验主题：基于大模型与多媒体编辑工具的新闻类 AI 短视频制作。
- 实验内容：围绕“英伟达 50 亿美元战略投资英特尔”这一新闻事件，利用多种 AI 工具完成文案撰写、画面生成、视频合成与剪辑，最终输出一条结构完整的短视频。
- 使用工具：
  - 文本与提示词生成：通义千问；
  - 图片生成：豆包（根据提示词生成图片）；
  - 文生视频/图文生成视频：sora2（根据图片与场景描述生成视频片段）；
  - 视频剪辑与整合：必剪（负责片段拼接、转场、字幕与导出）。
- 实验素材：
  - 文案素材来源于 `expr3/要求.txt` 中给出的新闻内容；
  - 图片需求与画面规划参考 `expr3/prompts.txt` 中的提示；
  - 实验过程中生成的图片和视频片段保存在 `expr3/images/` 等目录下，作为最终视频的构成元素。

## 二、实验原理

本实验聚焦于“多模态大模型 + 传统剪辑工具”的协同工作流程，其核心原理可概括为以下几个方面：

1. **大模型驱动的内容生成与提示词工程**：
	- 通义千问作为通用大模型，具备较强的自然语言理解与生成能力，可根据给定新闻材料自动生成更适合短视频叙事的分镜文案与图片/视频提示词；
	- 通过“提示词工程”（Prompt Engineering），可以控制生成内容的风格（科技感、金融感）、构图元素（logo、股价曲线、握手画面等）和色调基调（冷色调、蓝绿色等），从而提高后续图像生成的可控性与一致性。

2. **图像生成模型（豆包）与视觉叙事**：
	- 豆包根据文本提示词生成静态图片，是整个视频视觉素材的主要来源之一；
	- 通过将“nvidia 与 intel 的商标”“股价暴涨的 K 线/箭头”“两家企业合作握手”等概念抽象成清晰的提示词，即可得到多个候选画面，用于构成视频的关键帧或背景。

3. **文图到视频的跨模态生成（sora2）**：
	- sora2 支持将图片与简要场景描述作为输入，自动生成包含镜头运动、光影变化和过渡效果的短视频片段；
	- 可以理解为在静态图像的基础上进行时间维度上的“扩展”，通过补全中间帧、模拟镜头推拉摇移等方式，使画面更加生动；
	- 通过控制输入文本（如“缓慢推进镜头”“从左至右的平移”“背景出现股价曲线动态上扬”）可以一定程度上引导视频风格。

4. **传统非线性剪辑软件（必剪）的整合作用**：
	- 虽然 AI 可以自动生成文字、图片与视频片段，但最终成片仍然需要通过剪辑软件进行时间轴上的精细编排；
	- 必剪提供时间线编辑、音视频轨道管理、转场特效、字幕与背景音乐等功能，是将各个 AI 生成片段“串联成故事”的关键工具；
	- 将 AI 生成与人工剪辑结合，可以兼顾效率与可控性：AI 负责“生产素材”，必剪负责“结构和节奏”。

综上，实验本质上是一次“AI+工具链”协同的工作流设计实验，重点在于如何将不同工具的能力串联起来，完成从文本 → 图片 → 视频 → 成片的多阶段转换。

## 三、实验步骤（含具体提示词与参数）

本实验以“英伟达战略投资英特尔”为主线，参考 `prompts.txt` 中的三部分内容，将短视频分为三个画面段落。典型的操作步骤如下。

### 1. 使用通义千问生成结构化文案与提示词

1. **输入原始新闻材料**：
	- 将 `要求.txt` 中的内容复制到通义千问，要求其根据新闻事件生成适合 30–60 秒短视频的解说文案，并分为三段，对应：
	  1. 合作事件的宣布；
	  2. 股价变化与市场反应；
	  3. 合作意义与未来展望。
2. **生成画面提示词**：
	- 在通义千问中额外要求：针对每一段文案，生成 2–3 条用于图片生成的英文/中英文混合提示词，明确包含以下要素：
	  - 第一部分：NVIDIA 与 Intel 的 logo 同屏、高科技背景；
	  - 第二部分：股价上涨的 K 线图、绿色上涨箭头、市场行情屏幕；
	  - 第三部分：在两家 logo 下握手、合作、芯片与数据中心等元素；
	- 示例提示词（用于豆包）：
	  - “NVIDIA and Intel logos side by side, futuristic blue tech background, high contrast, 16:9”
	  - “Stock market chart with Intel stock price soaring 30%, green upward arrows, financial news style”
	  - “Two business people shaking hands under NVIDIA and Intel logos, symbolizing strategic partnership, cinematic lighting”。

### 2. 使用豆包生成图片素材

1. **按画面部分依次生成图片**：
	- 将通义千问给出的提示词逐条输入豆包，设置统一的画幅比例（例如 16:9 或 9:16，视目标平台而定）；
	- 每个部分生成 2–3 张候选图像，保证画面风格尽量统一（可以在提示词中固定“blue tech style”“flat illustration”或“3D render style”等描述）。
2. **保存与筛选**：
	- 将生成的图片按场景归类存入 `expr3/images/` 目录，例如：
	  - `images/part1_logo_01.png`, `images/part1_logo_02.png`；
	  - `images/part2_stock_01.png`, `images/part2_stock_02.png`；
	  - `images/part3_handshake_01.png`, `images/part3_handshake_02.png`；
	- 对比不同图片的构图、清晰度与风格一致性，选出最适合作为关键画面的 1–2 张图。

### 3. 使用 sora2 从图片与文本生成视频片段

1. **设定视频片段时长与风格**：
	- 在 sora2 中，新建 3 个片段项目，分别对应视频的三个章节；
	- 每个片段时长可设置为 6–10 秒，整体控制在 20–30 秒以内；
	- 统一选择科技感较强的风格，如冷色调灯光、细微粒子效果、缓慢镜头运动等。
2. **为每一部分提供图片与场景描述**：
	- 片段一（合作宣布）：
	  - 图片：选择 `images/part1_logo_xx.png`；
	  - 文本提示示例：
		 - “Slow zoom in on NVIDIA and Intel logos side by side, futuristic tech background, slight camera movement, subtle light flares”。
	- 片段二（股价上涨）：
	  - 图片：选择 `images/part2_stock_xx.png`；
	  - 文本提示示例：
		 - “Animated stock chart with Intel price soaring above 30%, dynamic green arrows rising, quick but smooth camera pan, financial news overlay style”。
	- 片段三（合作意义）：
	  - 图片：选择 `images/part3_handshake_xx.png`；
	  - 文本提示示例：
		 - “Two business silhouettes shaking hands under NVIDIA and Intel logos, background showing data centers and chips, slow cinematic camera move, hopeful lighting”。
3. **生成与导出视频片段**：
	- 等待 sora2 渲染完成后，检查画面是否与文案语气匹配（科技、财经、合作氛围）；
	- 若镜头运动过快/过慢，可通过调整提示词（slowly/quickly，cinematic/steady）重新生成；
	- 将满意的片段以 1080p 或平台推荐分辨率导出，命名为 `part1.mp4`, `part2.mp4`, `part3.mp4` 等。

### 4. 在必剪中进行剪辑与整合

1. **导入素材**：
	- 打开必剪，新建工程并设置视频分辨率和帧率（如 1920×1080, 30fps）；
	- 导入 sora2 生成的各段视频片段，以及背景音乐（若有）和配音音频（可以由任意 TTS 工具根据文案合成）。
2. **时间线编排**：
	- 将 `part1.mp4`、`part2.mp4`、`part3.mp4` 按顺序拖入视频轨道，并根据文案长度微调每段时长；
	- 在片段之间添加简单转场（如淡入淡出、交叉溶解），避免段落切换过于生硬。
3. **字幕与文字信息**：
	- 在关键画面上方添加简短文字，例如：
	  - “英伟达 50 亿美元战略投资英特尔”；
	  - “英特尔股价盘前暴涨超 30%”；
	  - “从竞争走向深度绑定的全新关系”；
	- 可以使用必剪的自动字幕功能导入配音音频并生成字幕，再进行人工校对与排版。
4. **音效与导出**：
	- 选择与科技财经主题相适配的轻电子背景音乐，控制音量不压制解说；
	- 最后检查整体节奏、画面与文案是否同步，确认无明显卡顿或画质问题后以 MP4 格式导出成片。

## 四、实验结果

1. **最终成片效果**：
	- 视频整体时长控制在 20–40 秒之间，包含开场 logo 画面、股价上涨画面以及合作握手与未来展望画面三大段落；
	- 画面风格较为统一，统一采用蓝绿科技色调和简洁的信息图表，使观众能快速抓住“合作 + 股价 + 未来”的核心信息；
	- 文案与画面内容对应清晰：第一段聚焦“宣布合作”，第二段强化“股价反应”，第三段总结“深度绑定与未来趋势”。

2. **工具协同表现**：
	- 通义千问在生成分镜文案与提示词方面大幅减少了手动构思时间，能快速得到多种风格备选；
	- 豆包生成的图片清晰度与构图质量较好，并且通过统一提示词可以在一定程度上保持画面风格一致性；
	- sora2 在将静态图转为动态视频方面效果自然，镜头运动与光影变化提升了整体观看感；
	- 必剪将上述素材有效整合，并通过转场、字幕与配音进一步提升了成片的专业感。

## 五、实验总结与分析

1. **对 AI 工具链的整体认识**：
	- 本实验展示了“通义千问 → 豆包 → sora2 → 必剪”的完整 AI 视频制作流程，从文本到图像再到视频，体现了多模态大模型在内容生产中的协同能力；
	- 相比传统完全手工制作的流程，AI 可以在素材生成阶段显著提升效率，使创作者更专注于结构设计与节奏把控。

2. **优点分析**：
	- **效率高**：大部分视觉素材由 AI 生成，减少了手动绘制或拍摄的成本；
	- **易于迭代**：不满意的文案、图片或视频片段可以通过修改提示词快速重新生成；
	- **风格可控**：通过在提示词中控制色调、构图与风格标签，能够在一定范围内保证整体视觉的一致性。

3. **存在的问题与局限**：
	- **细节可控性有限**：有时 AI 生成的画面细节与需求不完全一致，需要多次尝试或在必剪中通过裁剪遮挡来修正；
	- **品牌与版权问题**：在涉及真实品牌 logo（如 NVIDIA 和 Intel）时，需要注意商标使用的合规与平台审核规定；
	- **生成稳定性差异**：不同模型对同一提示词的响应存在随机性，有时会出现风格漂移或不符合预期的结果，需要人工筛选。

4. **改进与展望**：
	- 后续可以尝试引入更精细的“故事板”设计，在通义千问中直接生成带时间标注的分镜脚本，再交由豆包和 sora2 分段制作；
	- 可将 TTS（文本转语音）与配音风格选择纳入统一流程，以进一步自动化解说音轨的生成；
	- 在更复杂的项目中，可以考虑使用更多轨道和复杂转场、特效，使 AI 生成的视频更接近专业级商业作品；
	- 随着多模态大模型能力的增强，有望将文案撰写、画面生成与剪辑决策进一步整合，形成“一键生成+人工微调”的视频生产范式。

通过本实验，我对如何将不同 AI 工具和传统剪辑软件组合使用有了系统性的理解，也体会到提示词设计、素材筛选和节奏把控在 AI 视频制作中的重要性，为后续制作更复杂的多媒体项目打下了实践基础。
