# 多媒体技术实验一：一维PCA和二维PCA识别特征脸

## 一、实验目的

1.  **理解主成分分析（PCA）的基本原理**：掌握如何通过统计方法提取数据的主要特征，理解协方差矩阵、特征值和特征向量在降维中的作用。
2.  **掌握二维主成分分析（2D-PCA）的改进之处**：理解 2D-PCA 如何直接基于图像矩阵进行运算，避免了高维向量化带来的计算负担。
3.  **实现人脸识别与重构**：利用 Python 和相关科学计算库（NumPy, Scikit-learn）实现基于 PCA 和 2D-PCA 的人脸特征提取、图像重构及简单的身份识别。
4.  **对比分析**：比较两种方法在图像重构效果、计算效率及识别准确率上的差异。

## 二、实验原理

### 1. 一维 PCA (Eigenfaces)
PCA 是一种经典的线性降维算法。在人脸识别中，通常称为“特征脸”（Eigenfaces）方法。
-   **向量化**：将 $h \times w$ 的二维人脸图像展开为 $N = h \times w$ 维的列向量。
-   **中心化**：计算所有样本的平均脸 $\bar{X}$，并将每个样本减去平均脸得到中心化数据 $X_{centered}$。
-   **协方差矩阵**：计算协方差矩阵 $C = \frac{1}{M-1} X_{centered} X_{centered}^T$（或使用 $X^T X$ 的技巧简化计算）。
-   **特征分解**：对协方差矩阵进行特征分解，得到特征值和特征向量。特征向量即为“特征脸”，代表了人脸图像在统计上的主要变化方向。
-   **降维与重构**：选取前 $k$ 个最大特征值对应的特征向量构成投影矩阵，将原图像投影到低维空间得到特征系数。通过特征系数与特征向量的线性组合可以重构图像。

### 2. 二维 PCA (2D-PCA)
2D-PCA 直接基于二维图像矩阵构造散度矩阵，无需将图像拉伸为向量。
-   **图像散度矩阵**：对于 $M$ 个图像样本 $A_i$ ($h \times w$)，计算其平均图像 $\bar{A}$。构造图像散度矩阵 $G = \frac{1}{M} \sum_{i=1}^M (A_i - \bar{A})^T (A_i - \bar{A})$。
-   **特征分解**：$G$ 是一个 $w \times w$ 的矩阵（通常远小于 PCA 的 $N \times N$）。对其进行特征分解，选取前 $k$ 个最大特征值对应的特征向量 $X_1, \dots, X_k$ 构成投影矩阵 $W$。
-   **特征提取**：将图像 $A_i$ 投影到 $W$ 上，得到特征矩阵 $Y_i = (A_i - \bar{A}) W$。
-   **重构**：利用 $Y_i$ 和 $W$ 可以重构图像 $\tilde{A}_i = Y_i W^T + \bar{A}$。

## 三、实验环境与数据说明

-   **编程语言**：Python 3
-   **主要库**：NumPy (矩阵运算), Matplotlib (绘图), Scikit-learn (数据加载与分类器)
-   **数据集**：Olivetti Faces 数据集
    -   包含 400 张人脸图像。
    -   共 40 个不同的人（ID: 0-39），每个人有 10 张不同表情或光照下的图像。
    -   图像格式：64x64 像素，灰度图，像素值归一化在 [0, 1] 之间。

## 四、实验步骤与结果

### 第一部分：一维 PCA (Eigenfaces)

#### 1. 数据加载与预处理
加载 Olivetti 数据集，将图像转换为向量形式（样本数 400，特征数 4096）。

```python
# 关键代码片段
faces = fetch_olivetti_faces(data_home=data_dir, shuffle=True, random_state=42)
X = faces.data  # (400, 4096)
mean_face = X.mean(axis=0)
X_centered = X - mean_face
```

**结果展示**：
-   成功加载 400 个样本，单张图片尺寸 64x64。
-   计算得到“平均脸”，展示了所有人脸的平均轮廓。

#### 2. 协方差矩阵与特征分解
计算协方差矩阵并求解特征值与特征向量。

```python
# 关键代码片段
cov_matrix = (X_centered.T @ X_centered) / (n_samples - 1)
eigvals, eigvecs = np.linalg.eigh(cov_matrix)
# 排序特征值和特征向量...
```

**结果展示**：
-   前 10 个特征值数值较大，随着索引增加迅速衰减，说明大部分信息集中在前几个主成分中。
-   **特征脸可视化**：前几个特征脸（Eigenfaces）看起来像模糊的人脸，捕捉了光照、脸型等主要变化；后续的特征脸则包含更多高频细节（如五官边缘）。

#### 3. 图像重构实验
使用不同数量的主成分 ($k$) 对人脸进行重构，观察保留信息量的变化。

-   **k=10**：重构图像非常模糊，仅能看清大致轮廓和光照方向。
-   **k=40**：五官位置基本清晰，能辨认出是人脸，但细节仍有缺失。
-   **k=120**：重构图像与原始图像非常接近，大部分细节得到保留。

#### 4. 人脸识别实验
将数据分为训练集和测试集（75% : 25%），使用前 80 个主成分提取特征，并利用 1-NN（最近邻）分类器进行识别。

```python
# 关键代码片段
k_feature = 80
pca_basis = eigvecs[:, :k_feature]
X_proj = X_centered @ pca_basis
# ... train_test_split ...
knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(X_train, y_train)
accuracy = knn.score(X_test, y_test)
```

**实验结果**：
-   使用前 80 个主成分的 1-NN 分类准确率约为 **0.900** (具体数值依随机种子略有波动)。
-   分类结果示例显示，大部分测试样本能被正确分类到对应的 ID。

---

### 第二部分：二维 PCA (2D-PCA)

#### 1. 散度矩阵构造与分解
计算图像均值矩阵，并构造 $64 \times 64$ 的图像散度矩阵 $G$。

```python
# 关键代码片段
mean_image = images.mean(axis=0)
scatter_matrix = np.zeros((w, w), dtype=np.float64)
for img in images:
    diff = img - mean_image
    scatter_matrix += diff.T @ diff
scatter_matrix /= n_samples
eigvals, eigvecs = np.linalg.eigh(scatter_matrix)
```

**结果展示**：
-   散度矩阵尺寸为 $64 \times 64$，远小于 1D-PCA 的 $4096 \times 4096$，计算速度极快。
-   累计能量曲线显示，前几个投影向量集中了绝大部分能量。

#### 2. 子重构与图像重构
展示单个投影向量带来的“子重构”图像，并累加前 $k$ 个投影分量进行完整重构。

-   **子重构**：每个投影向量 $X_k$ 贡献了一个秩为 1 的子图像矩阵。
-   **重构效果**：
    -   **k=5**：图像已经比较清晰，能辨认出基本面貌。
    -   **k=10**：重构质量很高，细节丰富。
    -   **k=20**：几乎与原图无异。

#### 3. 人脸识别实验
同样使用 1-NN 分类器，使用前 20 个投影向量生成的特征矩阵（拉直后）作为特征。

```python
# 关键代码片段
k_feature = 20
W_feature = eigvecs[:, :k_feature]
projected_features = [(img - mean_image) @ W_feature for img in images]
# ... train_test_split ...
knn.fit(X_train, y_train)
accuracy = knn.score(X_test, y_test)
```

**实验结果**：
-   使用前 20 个投影向量的 1-NN 分类准确率约为 **0.960** (具体数值依随机种子略有波动)。
-   相比 1D-PCA，2D-PCA 在使用更少的投影向量（维度更低）的情况下，往往能达到更高或相当的识别率。

## 五、实验结果分析

1.  **重构效果对比**：
    -   **1D-PCA** 需要较多的主成分（如 $k=40$ 或更多）才能获得较好的视觉效果。这是因为它将图像视为一维向量，破坏了像素间的空间邻域结构。
    -   **2D-PCA** 在 $k=5$ 或 $k=10$ 时就能获得非常清晰的重构图像。它利用了图像的行/列相关性，特征提取效率更高。

2.  **计算复杂度**：
    -   **1D-PCA** 涉及 $4096 \times 4096$ 的协方差矩阵（或者 $400 \times 400$ 的样本相关矩阵），计算量大，对内存要求高。
    -   **2D-PCA** 仅需处理 $64 \times 64$ 的散度矩阵，计算特征值分解非常迅速，适合处理高维图像数据。

3.  **识别准确率**：
    -   在本实验中，2D-PCA 的识别准确率（~96%）略高于 1D-PCA（~90%）。这表明 2D-PCA 提取的特征对于人脸识别任务更具判别力，且对光照和表情变化具有一定的鲁棒性。

## 六、心得体会

通过本次实验，我深入理解了 PCA 算法在图像处理领域的应用。
1.  **降维的本质**：PCA 通过寻找数据方差最大的方向来保留主要信息，这在图像压缩和去噪中非常有用。
2.  **维度的诅咒与解法**：直接处理高维图像向量（如 4096 维）会导致计算困难和过拟合风险。2D-PCA 提供了一种巧妙的思路，即直接在矩阵空间操作，既保留了空间结构，又大幅降低了计算维度。
3.  **理论与实践的结合**：通过编写代码，我直观地看到了“特征脸”的模样，以及不同 $k$ 值对重构图像的影响，这比单纯学习公式要深刻得多。
4.  **改进方向**：虽然 2D-PCA 效果很好，但它主要利用了行方向的信息。未来可以尝试双向 2D-PCA ((2D)$^2$PCA) 或结合其他非线性方法（如 Kernel PCA）来进一步提升性能。
